#!/usr/bin/env python3
"""
Persona Augmentation for Elder Scrolls NPC Dialogue

Research Justification:
- Welleck et al. (2019): Persona fields required for NLI-based PCR evaluation
- Target: 40-50% persona coverage (minimum viable)
- Current: 5% (CRITICAL - below threshold)

Strategy: Generic NPC Role Assignment (Strategy 2)
- Quick to implement
- Consistent across samples
- Enables proper evaluation
"""

import json
import random
from collections import defaultdict
from pathlib import Path
from typing import Dict, List

# ============================================================================
# GENERIC NPC PERSONA TEMPLATES
# ============================================================================

# Research basis: These align with actual NPC roles in Elder Scrolls games
NPC_PERSONAS = {
    'guard': [
        "I am a guard",
        "I protect the city and its citizens",
        "I enforce the law"
    ],
    'merchant': [
        "I am a merchant",
        "I sell goods to travelers and adventurers",
        "I seek profit through trade"
    ],
    'innkeeper': [
        "I am an innkeeper",
        "I provide food, drink, and lodging",
        "I hear many stories from travelers"
    ],
    'mage': [
        "I am a mage",
        "I study the arcane arts",
        "I value knowledge and magical power"
    ],
    'warrior': [
        "I am a warrior",
        "I fight for honor and glory",
        "I trust in steel and strength"
    ],
    'commoner': [
        "I am a common citizen",
        "I live a simple life in this land",
        "I go about my daily work"
    ],
    'noble': [
        "I am of noble birth",
        "I hold a position of authority",
        "I value tradition and order"
    ],
    'thief': [
        "I work in the shadows",
        "I value stealth and cunning",
        "I seek fortune through guile"
    ],
    'priest': [
        "I serve the divine",
        "I provide spiritual guidance",
        "I believe faith brings salvation"
    ],
    'scholar': [
        "I am a scholar",
        "I seek knowledge through study",
        "I value wisdom above all"
    ],
    'generic': [
        "I am an inhabitant of this world",
        "I have my own thoughts and experiences",
        "I interact with those who cross my path"
    ]
}

# Keyword-based role detection (from dialogue content)
ROLE_KEYWORDS = {
    'guard': ['guard', 'patrol', 'law', 'criminal', 'arrest', 'duty', 'watch', 'crime'],
    'merchant': ['sell', 'buy', 'trade', 'goods', 'wares', 'gold', 'price', 'coin', 'merchant'],
    'innkeeper': ['inn', 'tavern', 'room', 'bed', 'drink', 'mead', 'ale', 'food'],
    'mage': ['magic', 'spell', 'arcane', 'enchant', 'mage', 'wizard', 'college', 'magicka'],
    'warrior': ['fight', 'battle', 'sword', 'armor', 'warrior', 'combat', 'weapon', 'glory'],
    'priest': ['divine', 'temple', 'pray', 'blessing', 'god', 'faith', 'sacred', 'worship'],
    'noble': ['lord', 'lady', 'noble', 'court', 'king', 'queen', 'duke', 'earl'],
    'thief': ['steal', 'thief', 'guild', 'shadow', 'sneak', 'lockpick'],
    'scholar': ['study', 'book', 'learn', 'knowledge', 'research', 'library', 'scholar'],
}

# ============================================================================
# PERSONA INFERENCE FUNCTIONS
# ============================================================================

def infer_npc_role(dialogue_text: str) -> str:
    """
    Infer NPC role from dialogue content using keyword matching.
    
    Research basis: Context-derived personas are more accurate than random assignment
    but require more processing. This is a lightweight heuristic approach.
    
    Args:
        dialogue_text: The NPC's dialogue text
        
    Returns:
        Role string (e.g., 'guard', 'merchant', 'generic')
    """
    text_lower = dialogue_text.lower()
    
    # Score each role based on keyword matches
    role_scores = defaultdict(int)
    
    for role, keywords in ROLE_KEYWORDS.items():
        for keyword in keywords:
            if keyword in text_lower:
                role_scores[role] += 1
    
    # Return highest scoring role, or 'generic' if no matches
    if role_scores:
        return max(role_scores.items(), key=lambda x: x[1])[0]
    return 'generic'


def add_persona_to_record(record: Dict) -> Dict:
    """
    Add persona field to a record if it's missing or empty.
    
    Research requirement: Persona fields enable NLI-based consistency evaluation
    
    Strategy:
    1. If persona exists and non-empty: Keep it
    2. If persona missing/empty:
       a. Try to infer from dialogue context (keyword matching)
       b. Use generic NPC role as fallback
    
    Args:
        record: Dialogue record dict
        
    Returns:
        Record with persona field populated
    """
    # Skip if persona already exists and non-empty
    if record.get('persona') and len(record['persona']) > 0:
        return record
    
    # Get first NPC dialogue turn for role inference
    dialogue_text = ""
    for turn in record.get('dialog', []):
        if turn.get('role') == 'npc':
            dialogue_text = turn.get('text', '')
            break
    
    # Infer role from dialogue content
    if dialogue_text:
        role = infer_npc_role(dialogue_text)
    else:
        role = 'generic'
    
    # Assign persona based on inferred role
    record['persona'] = NPC_PERSONAS[role].copy()
    
    return record


# ============================================================================
# BATCH PROCESSING
# ============================================================================

def augment_dataset(input_path: str, output_path: str) -> Dict[str, int]:
    """
    Augment an entire dataset with personas.
    
    Args:
        input_path: Path to input .jsonl file
        output_path: Path to output .jsonl file (can be same as input)
        
    Returns:
        Stats dict with counts
    """
    print(f"Reading from: {input_path}")
    
    # Load all records
    records = []
    with open(input_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                record = json.loads(line)
                records.append(record)
            except json.JSONDecodeError:
                continue
    
    print(f"Loaded {len(records):,} records")
    
    # Track statistics
    stats = {
        'total': len(records),
        'had_persona': 0,
        'added_persona': 0,
        'by_role': defaultdict(int)
    }
    
    # Augment each record
    print("Augmenting personas...")
    augmented_records = []
    
    for record in records:
        had_persona = bool(record.get('persona') and len(record['persona']) > 0)
        
        if had_persona:
            stats['had_persona'] += 1
            augmented_records.append(record)
        else:
            # Infer role for statistics
            dialogue_text = ""
            for turn in record.get('dialog', []):
                if turn.get('role') == 'npc':
                    dialogue_text = turn.get('text', '')
                    break
            
            role = infer_npc_role(dialogue_text) if dialogue_text else 'generic'
            stats['by_role'][role] += 1
            stats['added_persona'] += 1
            
            # Add persona
            augmented_record = add_persona_to_record(record)
            augmented_records.append(augmented_record)
    
    # Save augmented dataset
    print(f"Writing to: {output_path}")
    with open(output_path, 'w', encoding='utf-8') as f:
        for record in augmented_records:
            f.write(json.dumps(record) + '\n')
    
    return stats


# ============================================================================
# VALIDATION
# ============================================================================

def validate_augmentation(file_path: str):
    """
    Validate that persona augmentation worked correctly.
    
    Checks:
    - All records have persona fields
    - Personas are non-empty
    - Distribution of personas is reasonable
    """
    print(f"\nValidating: {file_path}")
    
    total = 0
    with_persona = 0
    persona_lengths = []
    role_distribution = defaultdict(int)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                record = json.loads(line)
                total += 1
                
                persona = record.get('persona', [])
                if persona and len(persona) > 0:
                    with_persona += 1
                    persona_lengths.append(len(persona))
                    
                    # Try to identify role from persona text
                    persona_text = ' '.join(persona).lower()
                    for role in NPC_PERSONAS.keys():
                        if role in persona_text:
                            role_distribution[role] += 1
                            break
                    
            except json.JSONDecodeError:
                continue
    
    coverage = with_persona / total * 100 if total > 0 else 0
    
    print(f"\nValidation Results:")
    print(f"  Total records: {total:,}")
    print(f"  With persona: {with_persona:,} ({coverage:.1f}%)")
    
    if persona_lengths:
        avg_len = sum(persona_lengths) / len(persona_lengths)
        print(f"  Avg persona length: {avg_len:.1f} statements")
    
    if coverage >= 95:
        print(f"  âœ… EXCELLENT persona coverage!")
    elif coverage >= 80:
        print(f"  âœ… GOOD persona coverage")
    elif coverage >= 40:
        print(f"  âš ï¸  ACCEPTABLE persona coverage (meets minimum)")
    else:
        print(f"  ðŸ”´ CRITICAL: Low persona coverage!")
    
    print(f"\nRole Distribution:")
    for role, count in sorted(role_distribution.items(), key=lambda x: -x[1])[:10]:
        pct = count / total * 100 if total > 0 else 0
        print(f"    {role}: {count:,} ({pct:.1f}%)")


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """
    Main execution: Augment all three splits.
    """
    print("=" * 80)
    print("PERSONA AUGMENTATION FOR NPC DIALOGUE")
    print("Research-Backed Fix for Low Coverage")
    print("=" * 80)
    
    # Paths
    base_dir = Path("data/processed/v2")
    
    splits = ['train', 'val', 'test']
    all_stats = {}
    
    for split in splits:
        print(f"\n{'=' * 80}")
        print(f"AUGMENTING {split.upper()} SET")
        print(f"{'=' * 80}")
        
        input_path = base_dir / f"{split}.jsonl"
        output_path = base_dir / f"{split}.jsonl"  # Overwrite in place
        
        if not input_path.exists():
            print(f"  âš ï¸  File not found: {input_path}")
            continue
        
        # Augment
        stats = augment_dataset(str(input_path), str(output_path))
        all_stats[split] = stats
        
        # Report
        total = stats['total']
        had = stats['had_persona']
        added = stats['added_persona']
        
        print(f"\n{split.upper()} Statistics:")
        print(f"  Total records: {total:,}")
        print(f"  Already had persona: {had:,} ({had/total*100:.1f}%)")
        print(f"  Added persona: {added:,} ({added/total*100:.1f}%)")
        print(f"  âœ… Final coverage: {(had+added)/total*100:.1f}%")
        
        print(f"\nRoles assigned:")
        for role, count in sorted(stats['by_role'].items(), key=lambda x: -x[1])[:5]:
            print(f"    {role}: {count:,}")
    
    # Validate all splits
    print(f"\n{'=' * 80}")
    print("VALIDATION")
    print(f"{'=' * 80}")
    
    for split in splits:
        file_path = base_dir / f"{split}.jsonl"
        if file_path.exists():
            validate_augmentation(str(file_path))
    
    # Final summary
    print(f"\n{'=' * 80}")
    print("AUGMENTATION COMPLETE")
    print(f"{'=' * 80}")
    
    print("\nSummary:")
    for split, stats in all_stats.items():
        total = stats['total']
        final_coverage = (stats['had_persona'] + stats['added_persona']) / total * 100
        print(f"  {split.upper()}: {final_coverage:.1f}% persona coverage")
    
    print("\nâœ… Your dataset now meets research requirements!")
    print("\nNext steps:")
    print("1. Re-run validation: python validate_data.py data/processed/v2/train.jsonl")
    print("2. Verify persona coverage > 95%")
    print("3. Manually review 10-20 samples")
    print("4. Proceed with training")


if __name__ == "__main__":
    main()